# Reinforcement Learning Papers

Plan is to follow a paper trail to build a first-principles foundation for reinforcement learning.

1. [Schulman, John, et al. "Trust region policy optimization." CoRR, abs/1502.05477 (2015).](https://arxiv.org/abs/1502.05477) 
  1. [Kakade, Sham, and John Langford. "Approximately optimal approximate reinforcement learning." ICML. Vol. 2. 2002.](http://www.cs.cmu.edu/~./jcl/papers/aoarl/Final.pdf) For the proof of conservative policy iteration update
  1. [Kakade, Sham. "A Natural Policy Gradient." NIPS. Vol. 14. 2001.](https://people.eecs.berkeley.edu/~pabbeel/cs287-fa09/readings/Kakade_natural_nips2002.pdf) Prior work for motivation
1. [Schulman, John, et al. "High-dimensional continuous control using generalized advantage estimation." arXiv preprint arXiv:1506.02438 (2015).](https://arxiv.org/abs/1506.02438)

## Asynchronous Approximation
1. [Tsitsiklis, John N. "Asynchronous stochastic approximation and Q-learning." Machine Learning 16.3 (1994): 185-202.](http://www.mit.edu/~jnt/Papers/J052-94-jnt-q.pdf)
1. 
